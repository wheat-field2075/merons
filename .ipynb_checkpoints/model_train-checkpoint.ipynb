{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Importing dependenceis\n",
    "    - Outside packages\n",
    "    - Custom classes\n",
    "\"\"\"\n",
    "\n",
    "# Outside packages\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import optim\n",
    "import albumentations as A\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "# Custom classes\n",
    "sys.path.append('./modules')\n",
    "from datatools import *\n",
    "from losstools import loss_function_wrapper\n",
    "from models import Hourglass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Declaring tunable hyperparameters\n",
    "\"\"\"\n",
    "\n",
    "# dataset generation hyperparameters\n",
    "patch_size = 200\n",
    "sigma = 9\n",
    "\n",
    "# training hyperparameters\n",
    "epochs = 0.5e3\n",
    "lr = 5e-4\n",
    "batch_size = 25\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Hourglass(depth=2).to(device)\n",
    "loss_func = loss_function_wrapper('gcel')\n",
    "transform = A.Compose([\n",
    "    A.RandomRotate90(p=1),\n",
    "    A.Transpose(p=0.5),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "])\n",
    "opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "# performance logger parameters\n",
    "write = False\n",
    "save_model = False\n",
    "if write or save_model:\n",
    "    folder = './active/2023.08.02 model_depth'\n",
    "    model_name = 'depth={}, gce'.format(3)\n",
    "if write:\n",
    "    writer = SummaryWriter('./{}/runs/{}'.format(folder, model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Images #####\n",
      "Copying: 20190822_movie_01_SampleOldA1_120kV_81x2048x2048_30sec_Aligned 11.48.51 AM patch_000.jpg...done\n",
      "Copying: 20190822_movie_01_SampleOldA1_120kV_81x2048x2048_30sec_Aligned 11.48.51 AM patch_005.jpg...done\n",
      "Copying: 20190822_movie_01_SampleOldA1_120kV_81x2048x2048_30sec_Aligned 11.48.51 AM patch_010.jpg...done\n",
      "Copying: 20190822_movie_01_SampleOldA1_120kV_81x2048x2048_30sec_Aligned 11.48.51 AM patch_015.jpg...done\n",
      "Copying: 20190822_movie_01_SampleOldA1_120kV_81x2048x2048_30sec_Aligned 11.48.51 AM patch_020.jpg...done\n",
      "Copying: 20190822_movie_01_SampleOldA1_120kV_81x2048x2048_30sec_Aligned 11.48.51 AM patch_025.jpg...done\n",
      "Copying: 20190822_movie_01_SampleOldA1_120kV_81x2048x2048_30sec_Aligned 11.48.51 AM patch_030.jpg...done\n",
      "Copying: 20190822_movie_01_SampleOldA1_120kV_81x2048x2048_30sec_Aligned 11.48.51 AM patch_035.jpg...done\n",
      "Copying: 20190822_movie_01_SampleOldA1_120kV_81x2048x2048_30sec_Aligned 11.48.51 AM patch_040.jpg...done\n",
      "Copying: 20190822_movie_01_SampleOldA1_120kV_81x2048x2048_30sec_Aligned 11.48.51 AM patch_045.jpg...done\n",
      "Copying: 20190822_movie_01_SampleOldA1_120kV_81x2048x2048_30sec_Aligned 11.48.51 AM patch_050.jpg...done\n",
      "Copying: 20190822_movie_01_SampleOldA1_120kV_81x2048x2048_30sec_Aligned 11.48.51 AM patch_055.jpg...done\n",
      "Copying: 20190822_movie_01_SampleOldA1_120kV_81x2048x2048_30sec_Aligned 11.48.51 AM patch_060.jpg...done\n",
      "Copying: 20190822_movie_01_SampleOldA1_120kV_81x2048x2048_30sec_Aligned 11.48.51 AM patch_065.jpg...done\n",
      "Copying: 20190822_movie_01_SampleOldA1_120kV_81x2048x2048_30sec_Aligned 11.48.51 AM patch_070.jpg...done\n",
      "Copying: 20190822_movie_01_SampleOldA1_120kV_81x2048x2048_30sec_Aligned 11.48.51 AM patch_075.jpg...done\n",
      "Copying: 20190822_movie_01_SampleOldA1_120kV_81x2048x2048_30sec_Aligned 11.48.51 AM patch_080.jpg...done\n",
      "##### Creating masks...done #####\n",
      "##### Grid samples #####\n",
      "Making samples for: 20190822_movie_01_SampleOldA1_120kV_81x2048x2048_30sec_Aligned 11.48.51 AM patch_000.jpg...done\n",
      "Making samples for: 20190822_movie_01_SampleOldA1_120kV_81x2048x2048_30sec_Aligned 11.48.51 AM patch_005.jpg...done\n",
      "Making samples for: 20190822_movie_01_SampleOldA1_120kV_81x2048x2048_30sec_Aligned 11.48.51 AM patch_010.jpg...done\n",
      "Making samples for: 20190822_movie_01_SampleOldA1_120kV_81x2048x2048_30sec_Aligned 11.48.51 AM patch_015.jpg...done\n",
      "Making samples for: 20190822_movie_01_SampleOldA1_120kV_81x2048x2048_30sec_Aligned 11.48.51 AM patch_020.jpg...done\n",
      "Making samples for: 20190822_movie_01_SampleOldA1_120kV_81x2048x2048_30sec_Aligned 11.48.51 AM patch_025.jpg...done\n",
      "Making samples for: 20190822_movie_01_SampleOldA1_120kV_81x2048x2048_30sec_Aligned 11.48.51 AM patch_030.jpg...done\n",
      "Making samples for: 20190822_movie_01_SampleOldA1_120kV_81x2048x2048_30sec_Aligned 11.48.51 AM patch_035.jpg...done\n",
      "Making samples for: 20190822_movie_01_SampleOldA1_120kV_81x2048x2048_30sec_Aligned 11.48.51 AM patch_040.jpg...done\n",
      "Making samples for: 20190822_movie_01_SampleOldA1_120kV_81x2048x2048_30sec_Aligned 11.48.51 AM patch_045.jpg...done\n",
      "Making samples for: 20190822_movie_01_SampleOldA1_120kV_81x2048x2048_30sec_Aligned 11.48.51 AM patch_050.jpg...done\n",
      "Making samples for: 20190822_movie_01_SampleOldA1_120kV_81x2048x2048_30sec_Aligned 11.48.51 AM patch_055.jpg...done\n",
      "Making samples for: 20190822_movie_01_SampleOldA1_120kV_81x2048x2048_30sec_Aligned 11.48.51 AM patch_060.jpg...done\n",
      "Making samples for: 20190822_movie_01_SampleOldA1_120kV_81x2048x2048_30sec_Aligned 11.48.51 AM patch_065.jpg...done\n",
      "Making samples for: 20190822_movie_01_SampleOldA1_120kV_81x2048x2048_30sec_Aligned 11.48.51 AM patch_070.jpg...done\n",
      "Making samples for: 20190822_movie_01_SampleOldA1_120kV_81x2048x2048_30sec_Aligned 11.48.51 AM patch_075.jpg...done\n",
      "Making samples for: 20190822_movie_01_SampleOldA1_120kV_81x2048x2048_30sec_Aligned 11.48.51 AM patch_080.jpg...done\n",
      "##### Loading dataset #####\n",
      "Loading samples for: 20190822_movie_01_SampleOldA1_120kV_81x2048x2048_30sec_Aligned 11.48.51 AM patch_000.jpg...done\n",
      "Loading samples for: 20190822_movie_01_SampleOldA1_120kV_81x2048x2048_30sec_Aligned 11.48.51 AM patch_005.jpg...done\n",
      "Loading samples for: 20190822_movie_01_SampleOldA1_120kV_81x2048x2048_30sec_Aligned 11.48.51 AM patch_010.jpg...done\n",
      "Loading samples for: 20190822_movie_01_SampleOldA1_120kV_81x2048x2048_30sec_Aligned 11.48.51 AM patch_015.jpg...done\n",
      "Loading samples for: 20190822_movie_01_SampleOldA1_120kV_81x2048x2048_30sec_Aligned 11.48.51 AM patch_020.jpg...done\n",
      "Loading samples for: 20190822_movie_01_SampleOldA1_120kV_81x2048x2048_30sec_Aligned 11.48.51 AM patch_025.jpg...done\n",
      "Loading samples for: 20190822_movie_01_SampleOldA1_120kV_81x2048x2048_30sec_Aligned 11.48.51 AM patch_030.jpg...done\n",
      "Loading samples for: 20190822_movie_01_SampleOldA1_120kV_81x2048x2048_30sec_Aligned 11.48.51 AM patch_035.jpg...done\n",
      "Loading samples for: 20190822_movie_01_SampleOldA1_120kV_81x2048x2048_30sec_Aligned 11.48.51 AM patch_040.jpg...done\n",
      "Loading samples for: 20190822_movie_01_SampleOldA1_120kV_81x2048x2048_30sec_Aligned 11.48.51 AM patch_045.jpg...done\n",
      "Loading samples for: 20190822_movie_01_SampleOldA1_120kV_81x2048x2048_30sec_Aligned 11.48.51 AM patch_050.jpg...done\n",
      "Loading samples for: 20190822_movie_01_SampleOldA1_120kV_81x2048x2048_30sec_Aligned 11.48.51 AM patch_055.jpg...done\n",
      "Loading samples for: 20190822_movie_01_SampleOldA1_120kV_81x2048x2048_30sec_Aligned 11.48.51 AM patch_060.jpg...done\n",
      "Loading samples for: 20190822_movie_01_SampleOldA1_120kV_81x2048x2048_30sec_Aligned 11.48.51 AM patch_065.jpg...done\n",
      "Loading samples for: 20190822_movie_01_SampleOldA1_120kV_81x2048x2048_30sec_Aligned 11.48.51 AM patch_070.jpg...done\n",
      "Loading samples for: 20190822_movie_01_SampleOldA1_120kV_81x2048x2048_30sec_Aligned 11.48.51 AM patch_075.jpg...done\n",
      "Loading samples for: 20190822_movie_01_SampleOldA1_120kV_81x2048x2048_30sec_Aligned 11.48.51 AM patch_080.jpg...done\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Constructing a pipeline to control how data is used by the model\n",
    "    - Temporary dataset creation: split dataset's patches into training and validation groups\n",
    "        * use 20190822...11.48.51 AM patch_[range(5, 76, 5)].jpg for training\n",
    "        * use 20190822...11.48.51 AM patch_[80].jpg for validation\n",
    "    - Dataloader creation: package lists of patches into torch Dataloaders\n",
    "\"\"\"\n",
    "\n",
    "# Temporary dataset creation\n",
    "parent_dir = make_dataset('./dataset',\n",
    "                          sigma=sigma,\n",
    "                          patch_size=patch_size)\n",
    "exclude_list = ['20190822_movie_01_SampleOldA1_120kV_81x2048x2048_30sec_Aligned 11.48.51 AM patch_080.jpg']\n",
    "train_ds, val_ds = load_temp_dataset(parent_dir, exclude_list)\n",
    "\n",
    "# Dataloader creation\n",
    "train_ds = MapDataset(train_ds)\n",
    "val_ds = MapDataset(val_ds)\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, shuffle=True, batch_size=batch_size)\n",
    "val_loader = torch.utils.data.DataLoader(val_ds, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                   | 0/500 [00:05<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(int(epochs))):\n",
    "    \"\"\"Training\"\"\"\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    for x, y in train_loader:\n",
    "        # transform data and send to device\n",
    "        x, y = transform_data(x, y, transform)\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        # make prediction and calculate loss\n",
    "        pred = model(x)\n",
    "        loss = loss_func(pred, y)\n",
    "        total_train_loss += loss\n",
    "        # backpropogration\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "    \"\"\"Validation\"\"\"\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        for x, y in val_loader:\n",
    "            # transform data and send to device\n",
    "            x, y = transform_data(x, y, transform)\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            # make prediction and calculate loss\n",
    "            pred = model(x)\n",
    "            loss = loss_func(pred, y)\n",
    "            total_val_loss += loss\n",
    "\n",
    "    # calculate average loss from aggregate\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "\n",
    "    # record performance statistics and save model, if necessary\n",
    "    if write:\n",
    "        writer.add_scalar('train_loss', avg_train_loss, epoch)\n",
    "        writer.add_scalar('val_loss', avg_val_loss, epoch)\n",
    "    if save_model:\n",
    "        if (epoch + 1) % 100 == 0:\n",
    "            model_param_path = './{}/model_saves/{}, epoch={:05}.pth'.format(folder, model_name, epoch + 1)\n",
    "            torch.save(model.state_dict(), model_param_path)\n",
    "\n",
    "# close performance logger, if necessary\n",
    "if write:\n",
    "    writer.flush()\n",
    "    writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
