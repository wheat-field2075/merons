{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Importing dependenceis\n",
    "    - Outside packages\n",
    "    - Custom classes\n",
    "\"\"\"\n",
    "\n",
    "# Outside packages\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import optim\n",
    "import albumentations as A\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "# Custom classes\n",
    "sys.path.append('./modules')\n",
    "from datatools1 import make_dataset, load_temp_dataset\n",
    "from datatools2 import MapDataset, transform_data\n",
    "from datatools3 import get_pr_image\n",
    "from losstools import loss_function_wrapper\n",
    "from models import Hourglass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Declaring tunable hyperparameters\n",
    "\"\"\"\n",
    "\n",
    "# dataset generation hyperparameters\n",
    "patch_size = 200\n",
    "sigma = 9\n",
    "\n",
    "# training hyperparameters\n",
    "epochs = 2.5e3\n",
    "lr = 5e-4\n",
    "batch_size = 25\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Hourglass(depth=1).to(device)\n",
    "loss_func = loss_function_wrapper('gcel')\n",
    "transform = A.Compose([\n",
    "    A.RandomRotate90(p=1),\n",
    "    A.Transpose(p=0.5),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "])\n",
    "opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# performance logger parameters\n",
    "write = False\n",
    "save_model = False\n",
    "if write or save_model:\n",
    "    folder = './active/2023.08.15 model_depth'\n",
    "    model_name = 'depth={}, gce'.format(1)\n",
    "if write:\n",
    "    writer = SummaryWriter('./{}/runs/{}'.format(folder, model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Constructing a pipeline to control how data is used by the model\n",
    "    - Temporary dataset creation: split dataset's patches into training and validation groups\n",
    "        * use 20190822...11.48.51 AM patch_[range(5, 76, 5)].jpg for training\n",
    "        * use 20190822...11.48.51 AM patch_[80].jpg for validation\n",
    "    - Dataloader creation: package lists of patches into torch Dataloaders\n",
    "\"\"\"\n",
    "\n",
    "# Temporary dataset creation\n",
    "# parent_dir = make_dataset('./dataset',\n",
    "#                           sigma=sigma,\n",
    "#                           patch_size=patch_size)\n",
    "parent_dir = './temp_datasets/ds_19'\n",
    "exclude_list = ['20190822_movie_01_SampleOldA1_120kV_81x2048x2048_30sec_Aligned 11.48.51 AM patch_080.jpg']\n",
    "train_ds, val_ds = load_temp_dataset(parent_dir, exclude_list)\n",
    "\n",
    "# Dataloader creation\n",
    "train_ds = MapDataset(train_ds)\n",
    "val_ds = MapDataset(val_ds)\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, shuffle=True, batch_size=batch_size)\n",
    "val_loader = torch.utils.data.DataLoader(val_ds, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in tqdm(range(int(epochs))):\n",
    "    \"\"\"Training\"\"\"\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    for x, y in train_loader:\n",
    "        # transform data and send to device\n",
    "        x, y = transform_data(x, y, transform)\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        # make prediction and calculate loss\n",
    "        pred = model(x)\n",
    "        loss = loss_func(pred, y)\n",
    "        total_train_loss += loss\n",
    "        # backpropogration\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "        \"\"\"Validation\"\"\"\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        for x, y in val_loader:\n",
    "            # transform data and send to device\n",
    "            x, y = transform_data(x, y, transform)\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            # make prediction and calculate loss\n",
    "            pred = model(x)\n",
    "            loss = loss_func(pred, y)\n",
    "            total_val_loss += loss\n",
    "            \n",
    "    # calculate precision and recall\n",
    "    total_precision = 0\n",
    "    total_recall = 0\n",
    "    \n",
    "    for image_name in exclude_list:\n",
    "        precision_recall = get_pr_image(parent_dir, image_name, model, patch_size, device)\n",
    "        total_precision += precision_recall[0]\n",
    "        total_recall += precision_recall[1]\n",
    "        \n",
    "    average_precision = total_precision / len(exclude_list)\n",
    "    average_recall = total_recall / len(exclude_list)\n",
    "\n",
    "    # calculate average loss from aggregate\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "\n",
    "    # record performance statistics and save model, if necessary\n",
    "    if write:\n",
    "        writer.add_scalar('train_loss', avg_train_loss, epoch)\n",
    "        writer.add_scalar('val_loss', avg_val_loss, epoch)\n",
    "        writer.add_scalar('average_precision', average_precision, epoch)\n",
    "        writer.add_scalar('average_recall', average_recall, epoch)\n",
    "    if save_model:\n",
    "        if (epoch + 1) % 50 == 0:\n",
    "            model_param_path = './{}/model_saves/{}, epoch={:05}.pth'.format(folder, model_name, epoch + 1)\n",
    "            torch.save(model.state_dict(), model_param_path)\n",
    "\n",
    "# close performance logger, if necessary\n",
    "if write:\n",
    "    writer.flush()\n",
    "    writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "merons",
   "language": "python",
   "name": "merons"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
