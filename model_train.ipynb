{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Importing dependencies\n",
    "    - Outside packages\n",
    "    - Custom classes\n",
    "\"\"\"\n",
    "\n",
    "# Outside packages\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import shutil\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import albumentations as A\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "# Custom classes\n",
    "sys.path.append('./modules')\n",
    "from model_tools import Hourglass\n",
    "from temp_dataset_tools import make_dataset\n",
    "from loss_tools import loss_function_wrapper\n",
    "from data_tools import MapDataset, transform_data, get_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Check for correct inputs if run from CLI\n",
    "\"\"\"\n",
    "usage_message = \"Usage:\\tmodel_train.py label write\\n\\n\\tlabel (int): the corresponding label of interest\\n\\twrite (bool): whether or not to write performance logs and save model states\"\n",
    "\n",
    "if len(sys.argv) != 2:\n",
    "    if len(sys.argv) != 3:\n",
    "        print(usage_message)\n",
    "        raise Exception\n",
    "    if type(eval(sys.argv[1])) != int:\n",
    "        print(usage_message)\n",
    "        raise TypeError\n",
    "    if type(eval(sys.argv[2])) != bool:\n",
    "        print(usage_message)\n",
    "        raise TypeError\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Declaring tunable hyperparameters\n",
    "\"\"\"\n",
    "\n",
    "# dataset generation hyperparameters\n",
    "label = 1 if len(sys.argv) == 2 else eval(sys.argv[1])\n",
    "sigma = 9\n",
    "\n",
    "# training hyperparameters\n",
    "lr = 5e-4\n",
    "depth = 1\n",
    "epochs = 1e4\n",
    "batch_size = 7\n",
    "\n",
    "# create training objects\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Hourglass(depth=depth).to(device)\n",
    "loss_func = loss_function_wrapper('gcel')\n",
    "transform = A.Compose([\n",
    "    A.RandomRotate90(p=1),\n",
    "    A.Transpose(p=0.5),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "])\n",
    "opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# performance logger parameters\n",
    "test_category = '2023.12.24 I shouldn\\'t be working right now'\n",
    "model_name = 'gcel, label={}'.format(label)\n",
    "\n",
    "write = False if len(sys.argv) == 2 else eval(sys.argv[2])\n",
    "if write:\n",
    "    for path in ['./active', os.path.join('./active', test_category), os.path.join('./active', test_category, 'model_saves'), os.path.join('./active', test_category, 'runs')]:\n",
    "        if os.path.exists(path) == False:\n",
    "            os.mkdir(path)\n",
    "        writer = SummaryWriter(os.path.join('./active', test_category, 'runs', model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Constructing a pipeline to control how data is used by the model\n",
    "    - Temporary dataset creation: split dataset's patches into training and validation groups\n",
    "        * use 20190822...Aligned patch_[range(5, 76, 5)].jpg for training\n",
    "        * use 20190822...Aligned patch_[80].jpg for validation\n",
    "    - Dataloader creation: package lists of patches into torch Dataloaders\n",
    "\"\"\"\n",
    "\n",
    "# Temporary dataset creation\n",
    "parent_dir = make_dataset('./dataset', sigma=sigma, label=label)\n",
    "exclude_list = ['20190822_movie_01_SampleOldA1_120kV_81x2048x2048_30sec_Aligned patch_080.jpg.npy']\n",
    "train_ds, val_ds = ([], [])\n",
    "for image_name in os.listdir(os.path.join(parent_dir, 'images')):\n",
    "    if image_name[-4:] != '.npy':\n",
    "        continue\n",
    "    image, mask = np.load(os.path.join(parent_dir, 'images', image_name)), np.load(os.path.join(parent_dir, 'masks', image_name))\n",
    "    # if image_name in exclude_list:\n",
    "    #     val_ds.append([image[:1592, :1592], mask])\n",
    "    # else:\n",
    "    #     train_ds.append([image[:1592, :1592], mask])\n",
    "    if image_name in exclude_list:\n",
    "        val_ds.append([image, mask])\n",
    "    else:\n",
    "        train_ds.append([image, mask])\n",
    "\n",
    "# Dataloader creation\n",
    "train_ds = MapDataset(train_ds)\n",
    "val_ds = MapDataset(val_ds)\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, shuffle=True, batch_size=batch_size)\n",
    "val_loader = torch.utils.data.DataLoader(val_ds, shuffle=False, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 23/10000 [00:27<3:14:45,  1.17s/it]"
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(int(epochs))):\n",
    "    \"\"\"Training\"\"\"\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    for x, y in train_loader:\n",
    "        # transform data and send to device\n",
    "        x, y = transform_data(x, y, transform)\n",
    "        if len(x.shape) == 3:\n",
    "            x, y = x[:, None, :, :], y[:, None, :, :]\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        # make prediction and calculate loss\n",
    "        pred = model(x)\n",
    "        loss = loss_func(pred, y)\n",
    "        total_train_loss += loss\n",
    "        # backpropogration\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    \"\"\"Validation\"\"\"\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        total_val_precision = 0\n",
    "        total_val_recall = 0\n",
    "        total_val_f1 = 0\n",
    "        for x, y in val_loader:\n",
    "            # transform data and send to device\n",
    "            x, y = transform_data(x, y, transform)\n",
    "            if len(x.shape) == 3:\n",
    "                x, y = x[:, None, :, :], y[:, None, :, :]\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            # make prediction and calculate loss\n",
    "            pred = model(x)\n",
    "            loss = loss_func(pred, y)\n",
    "            total_val_loss += loss\n",
    "            # calculate other performance metrics\n",
    "            pred, y = pred.cpu().detach().numpy().squeeze(), y.cpu().detach().numpy().squeeze()\n",
    "            precision, recall, f1 = get_stats(pred, y)\n",
    "            total_val_precision += precision\n",
    "            total_val_recall += recall\n",
    "            total_val_f1 += f1\n",
    "\n",
    "    # calculate average loss from aggregate\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "    avg_val_precision = total_val_precision / len(train_loader)\n",
    "    avg_val_recall = total_val_recall / len(train_loader)\n",
    "    avg_val_f1 = total_val_f1 / len(train_loader)\n",
    "\n",
    "    # record performance statistics and save model, if necessary\n",
    "    if write:\n",
    "        writer.add_scalar('train_loss', avg_train_loss, epoch)\n",
    "        writer.add_scalar('val_loss', avg_val_loss, epoch)\n",
    "        writer.add_scalar('avg_val_precision', avg_val_precision, epoch)\n",
    "        writer.add_scalar('avg_val_recall', avg_val_recall, epoch)\n",
    "        writer.add_scalar('avg_val_f1', avg_val_f1, epoch)\n",
    "\n",
    "    if write:\n",
    "        if (epoch + 1) % 50 == 0:\n",
    "            model_save_path = os.path.join('./active', test_category, 'model_saves', model_name+\" epoch={:05}.pth\".format(epoch+1))\n",
    "            torch.save(model.state_dict(), model_save_path)\n",
    "\n",
    "# close performance logger, if necessary\n",
    "if write:\n",
    "    writer.flush()\n",
    "    writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "merons",
   "language": "python",
   "name": "merons"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
