{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Importing dependenceis\n",
    "    - Outside packages\n",
    "    - Custom classes\n",
    "\"\"\"\n",
    "\n",
    "# Outside packages\n",
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import albumentations as A\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "# Custom classes\n",
    "sys.path.append('./modules')\n",
    "from model_tools import Hourglass\n",
    "from temp_dataset_tools import make_dataset\n",
    "from loss_tools import loss_function_wrapper\n",
    "from data_tools import MapDataset, transform_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Declaring tunable hyperparameters\n",
    "\"\"\"\n",
    "\n",
    "# dataset generation hyperparameters\n",
    "label = 1\n",
    "sigma = 9\n",
    "\n",
    "# training hyperparameters\n",
    "lr = 5e-4\n",
    "depth = 1\n",
    "epochs = 2.5e3\n",
    "batch_size = 1\n",
    "\n",
    "# create training objects\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Hourglass(depth=depth).to(device)\n",
    "loss_func = loss_function_wrapper('gcel')\n",
    "transform = A.Compose([\n",
    "    A.RandomRotate90(p=1),\n",
    "    A.Transpose(p=0.5),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "])\n",
    "opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# performance logger parameters\n",
    "test_category = '2023.12.24 I shouldn\\'t be working right now'\n",
    "model_name = 'gcel, label={}'.format(label)\n",
    "\n",
    "write = False\n",
    "save_model = False\n",
    "if write or save_model:\n",
    "    if os.path.exists('./active') == False:\n",
    "        os.mkdir('./active')\n",
    "    os.mkdir(os.path.join('./active', test_category, 'model_saves'))\n",
    "    os.mkdir(os.path.join('./active', test_category, 'runs'))\n",
    "if write:\n",
    "    writer = SummaryWriter(os.path.join('./active', test_category, 'runs', model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Constructing a pipeline to control how data is used by the model\n",
    "    - Temporary dataset creation: split dataset's patches into training and validation groups\n",
    "        * use 20190822...11.48.51 AM patch_[range(5, 76, 5)].jpg for training\n",
    "        * use 20190822...11.48.51 AM patch_[80].jpg for validation\n",
    "    - Dataloader creation: package lists of patches into torch Dataloaders\n",
    "\"\"\"\n",
    "\n",
    "# Temporary dataset creation\n",
    "parent_dir = make_dataset('./dataset',\n",
    "                         sigma=sigma,\n",
    "                         label=label)\n",
    "exclude_list = ['20190822_movie_01_SampleOldA1_120kV_81x2048x2048_30sec_Aligned 11.48.51 AM patch_080.jpg.npy']\n",
    "train_ds, val_ds = ([], [])\n",
    "for image_name in os.listdir(os.path.join(parent_dir, 'images')):\n",
    "    if image_name[-4:] != '.npy':\n",
    "        continue\n",
    "    image, mask = np.load(os.path.join(parent_dir, 'images', image_name)), np.load(os.path.join(parent_dir, 'masks', image_name))\n",
    "    if image_name in exclude_list:\n",
    "        val_ds.append([image, mask])\n",
    "    else:\n",
    "        train_ds.append([image, mask])\n",
    "\n",
    "# Dataloader creation\n",
    "train_ds = MapDataset(train_ds)\n",
    "val_ds = MapDataset(val_ds)\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, shuffle=True, batch_size=batch_size)\n",
    "val_loader = torch.utils.data.DataLoader(val_ds, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 2/2500 [02:58<61:48:03, 89.06s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# backpropogration\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     opt\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 18\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m     opt\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     21\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Validation\"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/mambaforge/envs/py39/lib/python3.9/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    488\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    489\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/py39/lib/python3.9/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[38;5;66;03m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for epoch in tqdm(range(int(epochs))):\n",
    "    \"\"\"Training\"\"\"\n",
    "    model.train()\n",
    "    total_train_loss = 0\n",
    "    for x, y in train_loader:\n",
    "        # transform data and send to device\n",
    "        x, y = transform_data(x, y, transform)\n",
    "        if len(x.shape) == 3:\n",
    "            x, y = x[:, None, :, :], y[:, None, :, :]\n",
    "        x = x.to(device)\n",
    "        y = y.to(device)\n",
    "        # make prediction and calculate loss\n",
    "        pred = model(x)\n",
    "        loss = loss_func(pred, y)\n",
    "        total_train_loss += loss\n",
    "        # backpropogration\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "\n",
    "    \"\"\"Validation\"\"\"\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        total_val_loss = 0\n",
    "        for x, y in val_loader:\n",
    "            # transform data and send to device\n",
    "            x, y = transform_data(x, y, transform)\n",
    "            if len(x.shape) == 3:\n",
    "                x, y = x[:, None, :, :], y[:, None, :, :]\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            # make prediction and calculate loss\n",
    "            pred = model(x)\n",
    "            loss = loss_func(pred, y)\n",
    "            total_val_loss += loss\n",
    "\n",
    "    # calculate average loss from aggregate\n",
    "    avg_train_loss = total_train_loss / len(train_loader)\n",
    "    avg_val_loss = total_val_loss / len(val_loader)\n",
    "\n",
    "    # record performance statistics and save model, if necessary\n",
    "    if write:\n",
    "        writer.add_scalar('train_loss', avg_train_loss, epoch)\n",
    "        writer.add_scalar('val_loss', avg_val_loss, epoch)\n",
    "\n",
    "    if save_model:\n",
    "        if (epoch + 1) % 50 == 0:\n",
    "            model_save_path = os.path.join('./active', test_category, 'model_saves', model_name+\" epoch={:05}.pth\".format(epoch+1))\n",
    "            torch.save(model.state_dict(), model_save_path)\n",
    "\n",
    "# close performance logger, if necessary\n",
    "if write:\n",
    "    writer.flush()\n",
    "    writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
