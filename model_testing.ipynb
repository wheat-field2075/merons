{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Importing dependenceis\n",
    "    - Outside packages\n",
    "    - Custom classes\n",
    "\"\"\"\n",
    "\n",
    "# Outside packages\n",
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import optim\n",
    "import albumentations as A\n",
    "import json\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "from tensorboardX import SummaryWriter\n",
    "\n",
    "# Custom classes\n",
    "sys.path.append('./modules')\n",
    "from datatools import *\n",
    "from losstools import loss_function\n",
    "from models import Hourglass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Declaring tunable hyperparameters\n",
    "\"\"\"\n",
    "\n",
    "# dataset generation hyperparameters\n",
    "patch_size = 200\n",
    "sigma = 9\n",
    "\n",
    "# training hyperparameters\n",
    "epochs = 0.5e3\n",
    "lr = 5e-4\n",
    "batch_size = 25\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Hourglass(depth=2).to(device)\n",
    "loss_func = loss_function('gcel')\n",
    "transform = A.Compose([\n",
    "    A.RandomRotate90(p=1),\n",
    "    A.Transpose(p=0.5),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    A.VerticalFlip(p=0.5),\n",
    "])\n",
    "opt = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "# performance logger parameters\n",
    "write = False\n",
    "save_model = False\n",
    "if write or save_model:\n",
    "    folder = '2023.08.02 model_depth'\n",
    "    model_name = 'depth={}, gce'.format(3)\n",
    "if write:\n",
    "    writer = SummaryWriter('./{}/runs/{}'.format(folder, model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Constructing a pipeline to control how data is used by the model\n",
    "    - Temporary dataset creation: split dataset's patches into training and validation groups\n",
    "        * use 20190822...11.48.51 AM patch_[range(5, 76, 5)].jpg for training\n",
    "        * use 20190822...11.48.51 AM patch_[80].jpg for validation\n",
    "    - Dataloader creation: package lists of patches into torch Dataloaders\n",
    "\"\"\"\n",
    "\n",
    "# Temporary dataset creation\n",
    "parent_dir = make_dataset('./dataset',\n",
    "                          sigma=sigma,\n",
    "                          patch_size=patch_size)\n",
    "exclude_list = ['20190822_movie_01_SampleOldA1_120kV_81x2048x2048_30sec_Aligned 11.48.51 AM patch_080.jpg']\n",
    "train_ds, val_ds = load_temp_dataset(parent_dir, exclude_list)\n",
    "\n",
    "# Dataloader creation\n",
    "train_ds = MapDataset(train_ds)\n",
    "val_ds = MapDataset(val_ds)\n",
    "train_loader = torch.utils.data.DataLoader(train_ds, shuffle=True, batch_size=1)\n",
    "val_loader = torch.utils.data.DataLoader(val_ds, shuffle=False, batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view performance on patches (1/2)\n",
    "\n",
    "\"\"\"\n",
    "val_view_generator: lil generator function to view model's predictions on validation data. left is\n",
    "    source image, middle is the target, right is the model's prediction\n",
    "\"\"\"\n",
    "def val_view_generator(val_loader):\n",
    "    for x, y in val_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        pred = model(x)\n",
    "\n",
    "        plt.figure(figsize=[15, 5])\n",
    "        for index, target in enumerate([x, y, pred]):\n",
    "            plt.subplot(1, 3, index+1)\n",
    "            plt.axis('off')\n",
    "            target = target.detach().cpu().numpy().squeeze()\n",
    "            if index == 0:\n",
    "                plt.imshow(target, cmap='Greys_r')\n",
    "            else:\n",
    "                plt.imshow(target, cmap='jet')\n",
    "\n",
    "        yield 1\n",
    "\n",
    "val_gen = val_view_generator(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view performance on patches (2/2)\n",
    "\n",
    "next(val_gen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view performance on entire validation image\n",
    "\n",
    "val_image_name = '20190822_movie_01_SampleOldA1_120kV_81x2048x2048_30sec_Aligned 11.48.51 AM patch_080.jpg'\n",
    "val_image_path = os.path.join(parent_dir, 'images', val_image_name)\n",
    "val_mask_path = os.path.join(parent_dir, 'masks', val_image_name)\n",
    "\n",
    "val_image = np.array(Image.open(val_image_path))\n",
    "val_mask = np.array(Image.open(val_mask_path))\n",
    "pred_mask = np.zeros(val_mask.shape)\n",
    "\n",
    "def write_to_pred(y, x):\n",
    "    image_patch = val_image[y:y+patch_size, x:x+patch_size]\n",
    "    pred_patch = model(torch.Tensor(image_patch).to(device))\n",
    "    pred_patch = pred_patch.detch().cpu().numpy().squeeze()\n",
    "    pred_mask[y:y+patch_size, x:x+patch_size] = np.maximum(pred_mask[y:y+patch_size, x:x+patch_size],\n",
    "                                                          pred_patch)\n",
    "\n",
    "for y, x in itertools.product(range(0, val_image.shape[0] - patch_size, 100),\n",
    "                             range(0, val_image.shape[1] - patch_size, 100)):\n",
    "    write_to_pred(y, x)\n",
    "\n",
    "y = val_image.shape[0] - patch_size\n",
    "for x in range(0, val_image.shape[1] - patch_size, 100):\n",
    "    write_to_pred(y, x)\n",
    "\n",
    "x = val_image.shape[0] - patch_size\n",
    "for y in range(0, val_image.shape[0] - patch_size, 100):\n",
    "    write_to_pred(y, x)\n",
    "\n",
    "y, x = (val_image.shape[0] - patch_size, val_image.shape[1] - patch_size)\n",
    "write_to_pred(y, x)\n",
    "\n",
    "plt.figure(figsize=[15, 5])\n",
    "for index, target in enumerate([val_image, val_mask, pred_mask]):\n",
    "    plt.subplot(1, 3, index+1)\n",
    "    plt.axis('off')\n",
    "    if index == 0:\n",
    "        plt.imshow(target, cmap='Greys_r')\n",
    "    else:\n",
    "        plt.imshow(target, cmap='jet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
